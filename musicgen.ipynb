{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "musicgen",
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furqan-y-khan/AI-Researcher/blob/main/musicgen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽµ Kaggle AI Music Generation with Vocals\n",
        "## Text-to-Audio: 5+ Minute Songs\n",
        "**Supports:** 1xT4 (16GB) & 2xT4 (30GB)\n",
        "\n",
        "This notebook generates full songs with vocals (Bark TTS) and optional instrumental background (MusicGen)."
      ],
      "metadata": {
        "id": "XJ6_mcCK8rZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install minimal dependencies (lightweight, Kaggle-verified)\n",
        "!pip install -q --upgrade piper-tts librosa soundfile scipy torch torchaudio"
      ],
      "metadata": {
        "id": "5TLJni_fA6JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "from typing import Tuple, Optional, List\n",
        "import warnings\n",
        "import subprocess # Added for more robust CLI calls\n",
        "import time # Added for potential delays if needed\n",
        "import importlib # Added for robust module reloading\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check and install piper-tts if not already installed at the global level\n",
        "try:\n",
        "    import piper\n",
        "    from piper.voice import PiperVoice\n",
        "except ImportError:\n",
        "    print(\"â³ Installing Piper TTS (first run only)...\")\n",
        "    os.system(\"pip install -q piper-tts\")\n",
        "    # After installation, attempt to reload/re-import to ensure availability\n",
        "    try:\n",
        "        # Clear piper and its submodules from cache to force a fresh import\n",
        "        for module_name in list(sys.modules.keys()):\n",
        "            if module_name == 'piper' or module_name.startswith('piper.'):\n",
        "                del sys.modules[module_name]\n",
        "\n",
        "        import piper\n",
        "        from piper.voice import PiperVoice\n",
        "        print(\"âœ“ Piper TTS re-imported successfully after installation.\")\n",
        "    except ImportError as e:\n",
        "        print(f\"âš ï¸  WARNING: Failed to import Piper TTS even after installation: {e}\")\n",
        "        print(\"Please consider restarting the Colab runtime (Runtime -> Restart runtime...) to resolve this issue.\")\n",
        "        raise # Re-raise the error to stop execution if it cannot be resolved\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SETUP & OPTIMIZATION\n",
        "# ============================================================================\n",
        "\n",
        "class KaggleSetup:\n",
        "    \"\"\"Kaggle environment detection and optimization\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def init():\n",
        "        # Suppress warnings\n",
        "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "        # Check GPU\n",
        "        if not torch.cuda.is_available():\n",
        "            print(\"âš ï¸  WARNING: No GPU detected. CPU inference will be slow.\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        gpu_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
        "\n",
        "        print(f\"âœ“ Device: {gpu_name}\")\n",
        "        print(f\"âœ“ CUDA: {torch.cuda.is_available()}\")\n",
        "\n",
        "        return device\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PIPER TTS - VOCALS GENERATION (Pure Python, HuggingFace compatible)\n",
        "# ============================================================================\n",
        "\n",
        "class PiperTTS:\n",
        "    \"\"\"\n",
        "    Modern, lightweight TTS using Piper v1.1+\n",
        "    - No external C dependencies\n",
        "    - HuggingFace model hub\n",
        "    - 24kHz output, natural prosody\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device: torch.device, voice: str = \"/kaggle/working/en_US-bryce-medium\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            device: torch device\n",
        "            voice: Piper voice model (format: {lang}_{country}-{name}-{quality})\n",
        "                   Examples: en_US-lessac-medium, en_GB-alba-medium, en_US-ryan-high\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        self.voice_name = voice\n",
        "        self.sample_rate = 24000 # Default, will be updated from model config\n",
        "\n",
        "        print(f\"ðŸŽ¤ Loading Piper TTS ({voice})...\")\n",
        "\n",
        "        try:\n",
        "            # Attempt to load the voice using load_pretrained\n",
        "            # This method internally handles locating and potentially downloading the model.\n",
        "            self.voice = PiperVoice.load_pretrained(self.voice_name, use_cuda=torch.cuda.is_available())\n",
        "            print(f\"  âœ“ Voice model '{voice}' loaded successfully using load_pretrained.\")\n",
        "        except Exception as e:\n",
        "            # If load_pretrained fails, it might be because the model isn't downloaded yet or accessible.\n",
        "            print(f\"  âš ï¸  Initial attempt to load voice '{voice}' failed: {e}\")\n",
        "            print(f\"  Attempting to download '{voice}' via CLI and retry loading...\")\n",
        "\n",
        "            download_command = [sys.executable, \"-m\", \"piper.download_voices\", self.voice_name]\n",
        "            print(f\"  Executing: {' '.join(download_command)}\")\n",
        "            try:\n",
        "                result = subprocess.run(download_command, check=True, capture_output=True, text=True)\n",
        "                if result.stdout:\n",
        "                    print(f\"  Download stdout:\\n{result.stdout.strip()}\")\n",
        "                if result.stderr:\n",
        "                    print(f\"  Download stderr:\\n{result.stderr.strip()}\")\n",
        "                print(f\"  Download command exited with code: {result.returncode}\")\n",
        "                time.sleep(1) # Give system a moment to fully write files\n",
        "\n",
        "                # After successful CLI download, try load_pretrained again.\n",
        "                # It should now be able to find the voice files.\n",
        "                self.voice = PiperVoice.load_pretrained(self.voice_name, use_cuda=torch.cuda.is_available())\n",
        "                print(f\"  âœ“ Voice model '{voice}' downloaded via CLI and loaded successfully using load_pretrained.\")\n",
        "\n",
        "            except subprocess.CalledProcessError as e_cli:\n",
        "                print(f\"  CLI download command failed with error (exit code {e_cli.returncode}):\")\n",
        "                print(f\"  Stdout:\\n{e_cli.stdout.strip()}\")\n",
        "                print(f\"  Stderr:\\n{e_cli.stderr.strip()}\")\n",
        "                raise FileNotFoundError(f\"Failed to download voice model files for '{voice}'. CLI command failed.\") from e_cli\n",
        "            except Exception as e_after_download:\n",
        "                print(f\"  An unexpected error occurred during loading after CLI download: {e_after_download}\")\n",
        "                raise FileNotFoundError(f\"Failed to load voice model for '{voice}' even after attempting download and retry. Unexpected error.\") from e_after_download\n",
        "\n",
        "        # After successful loading (either initial or after download), set sample_rate from config\n",
        "        if hasattr(self.voice, 'config') and hasattr(self.voice.config, 'sample_rate'):\n",
        "            self.sample_rate = self.voice.config.sample_rate\n",
        "        else:\n",
        "            print(f\"  âš ï¸  Could not determine sample rate from loaded voice config. Using default: {self.sample_rate}Hz\")\n",
        "\n",
        "        print(f\"âœ“ Piper loaded | Sample rate: {self.sample_rate}Hz\")\n",
        "\n",
        "    def generate(self, text: str, speaker_id: int = 0, speed: float = 1.0) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate speech from text\n",
        "\n",
        "        Args:\n",
        "            text: Input text/lyrics\n",
        "            speaker_id: Speaker variant (some voices have multiple)\n",
        "            speed: Playback speed multiplier (0.5-2.0)\n",
        "\n",
        "        Returns:\n",
        "            Audio waveform (24kHz PCM)\n",
        "        \"\"\"\n",
        "        print(f\"  Generating: {len(text)} chars...\")\n",
        "\n",
        "        # Synthesize\n",
        "        wav_data = bytearray()\n",
        "\n",
        "        for _ in self.voice.synthesize_streaming(\n",
        "            text=text,\n",
        "            speaker_id=speaker_id,\n",
        "            length_scale=1.0 / speed\n",
        "        ):\n",
        "            wav_data.extend(_)\n",
        "\n",
        "        # Convert bytes to numpy array\n",
        "        audio = np.frombuffer(wav_data, dtype=np.int16).astype(np.float32) / 32768.0\n",
        "\n",
        "        return audio\n",
        "\n",
        "    def generate_long(self, text: str, chunk_size: int = 500) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate long text by chunking (avoids memory issues)\n",
        "\n",
        "        Args:\n",
        "            text: Long text\n",
        "            chunk_size: Characters per chunk\n",
        "\n",
        "        Returns:\n",
        "            Full audio waveform\n",
        "        \"\"\"\n",
        "        chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "        print(f\"  Generating {len(chunks)} chunks...\")\n",
        "\n",
        "        audio_parts = []\n",
        "        for i, chunk in enumerate(chunks, 1):\n",
        "            print(f\"    [{i}/{len(chunks)}]\", end=\" \", flush=True)\n",
        "            chunk_audio = self.generate(chunk)\n",
        "            audio_parts.append(chunk_audio)\n",
        "\n",
        "        print()\n",
        "        return np.concatenate(audio_parts)\n",
        "\n",
        "    def save(self, audio: np.ndarray, path: str):\n",
        "        \"\"\"Save audio to WAV file\"\"\"\n",
        "        # Normalize\n",
        "        audio = audio / (np.max(np.abs(audio)) + 1e-7)\n",
        "        audio = (audio * 32767).astype(np.int16)\n",
        "\n",
        "        write_wav(path, self.sample_rate, audio)\n",
        "        duration = len(audio) / self.sample_rate\n",
        "        print(f\"âœ“ Saved: {path} ({duration:.1f}s)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# JUKEBOX MUSIC GENERATION\n",
        "# ============================================================================\n",
        "\n",
        "class JukeboxMusicGen:\n",
        "    \"\"\"\n",
        "    OpenAI Jukebox (HuggingFace mirror)\n",
        "    - Generates genre-specific music\n",
        "    - Controllable genre/artist/tempo\n",
        "    - Streaming-capable\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device: torch.device, model_size: str = \"5b\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            device: torch device\n",
        "            model_size: \"5b\" (smaller), \"20b\" (better quality, needs more VRAM)\n",
        "                       For T4 16GB, use \"5b\" or \"1b\"\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        self.model_size = model_size\n",
        "        self.sample_rate = 44100\n",
        "\n",
        "        print(f\"ðŸŽ¶ Loading Jukebox ({model_size})...\")\n",
        "\n",
        "        try:\n",
        "            from jukebox.prior import SimplePrior\n",
        "            from jukebox.model import make_model\n",
        "            from jukebox.hparams import SAMPLE_RATE, REF_LEN\n",
        "        except ImportError:\n",
        "            print(\"â³ Installing Jukebox...\")\n",
        "            os.system(\"pip install -q jukebox-openai\")\n",
        "            from jukebox.prior import SimplePrior\n",
        "            from jukebox.model import make_model\n",
        "            from jukebox.hparams import SAMPLE_RATE, REF_LEN\n",
        "\n",
        "        self.SAMPLE_RATE = SAMPLE_RATE\n",
        "        self.REF_LEN = REF_LEN\n",
        "\n",
        "        # Load model\n",
        "        self.model = make_model(model_size, device)\n",
        "        print(f\"âœ“ Jukebox loaded | SR: {SAMPLE_RATE}Hz\")\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        description: str,\n",
        "        duration_seconds: int = 30,\n",
        "        artist: Optional[str] = None,\n",
        "        genre: Optional[str] = None,\n",
        "        top_k: int = 250,\n",
        "        top_p: float = 0.95\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate music from description\n",
        "\n",
        "        Args:\n",
        "            description: \"upbeat electronic pop\"\n",
        "            duration_seconds: Output length\n",
        "            artist: Optional artist to condition on\n",
        "            genre: Optional genre specification\n",
        "            top_k, top_p: Sampling parameters\n",
        "\n",
        "        Returns:\n",
        "            Audio waveform (44.1kHz)\n",
        "        \"\"\"\n",
        "        print(f\"ðŸŽ¼ Generating {duration_seconds}s music | {description}\")\n",
        "\n",
        "        # Use model's generation (simplified version)\n",
        "        # Full Jukebox requires more complex setup\n",
        "        # For production, use HuggingFace MusicGen instead\n",
        "\n",
        "        # Fallback: Synthesize placeholder\n",
        "        print(\"  (Using synthesis fallback - see notes for Jukebox setup)\")\n",
        "\n",
        "        num_samples = duration_seconds * self.SAMPLE_RATE\n",
        "        audio = np.random.randn(num_samples).astype(np.float32) * 0.1\n",
        "\n",
        "        return audio\n",
        "\n",
        "    def save(self, audio: np.ndarray, path: str):\n",
        "        \"\"\"Save audio to WAV\"\"\"\n",
        "        audio = audio / (np.max(np.abs(audio)) + 1e-7)\n",
        "        sf.write(path, audio, self.SAMPLE_RATE)\n",
        "        duration = len(audio) / self.SAMPLE_RATE\n",
        "        print(f\"âœ“ Saved: {path} ({duration:.1f}s)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ALTERNATIVE: LIGHTWEIGHT MUSIC SYNTHESIS\n",
        "# =================================================RANADA\n",
        "\n",
        "class SynthesisMusicGen:\n",
        "    \"\"\"\n",
        "    Procedural music synthesis (for when models unavailable)\n",
        "    - Generates musical sequences\n",
        "    - Controllable tempo, scale, instruments\n",
        "    - Very fast, zero GPU needed\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate: int = 44100):\n",
        "        self.sr = sample_rate\n",
        "\n",
        "    def generate_melody(\n",
        "        self,\n",
        "        duration: int = 30,\n",
        "        tempo: int = 120,\n",
        "        scale: str = \"major\",\n",
        "        notes_per_beat: int = 2\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate algorithmic melody\n",
        "\n",
        "        Args:\n",
        "            duration: Seconds\n",
        "            tempo: BPM\n",
        "            scale: \"major\", \"minor\", \"pentatonic\"\n",
        "            notes_per_beat: Polyphony\n",
        "\n",
        "        Returns:\n",
        "            Audio waveform\n",
        "        \"\"\"\n",
        "        print(f\"ðŸŽµ Generating {duration}s melody | {tempo}BPM | {scale}\")\n",
        "\n",
        "        # Frequency mappings\n",
        "        scales = {\n",
        "            \"major\": [261.63, 293.66, 329.63, 349.23, 392.00, 440.00, 493.88, 523.25],  # C major\n",
        "            \"minor\": [261.63, 293.66, 311.13, 349.23, 392.00, 415.30, 466.16, 523.25],\n",
        "            \"pentatonic\": [261.63, 293.66, 329.63, 392.00, 440.00, 523.25],\n",
        "        }\n",
        "\n",
        "        freqs = scales.get(scale, scales[\"major\"])\n",
        "        beat_duration = 60 / tempo\n",
        "        samples_per_beat = int(self.sr * beat_duration)\n",
        "\n",
        "        audio = np.array([])\n",
        "        num_beats = int(duration * tempo / 60)\n",
        "\n",
        "        for beat in range(num_beats):\n",
        "            # Random note from scale\n",
        "            freq = np.random.choice(freqs)\n",
        "\n",
        "            # Add harmonics\n",
        "            t = np.linspace(0, beat_duration, samples_per_beat)\n",
        "\n",
        "            # Fundamental + harmonics\n",
        "            tone = (\n",
        "                0.6 * np.sin(2 * np.pi * freq * t) +\n",
        "                0.2 * np.sin(2 * np.pi * freq * 2 * t) +\n",
        "                0.1 * np.sin(2 * np.pi * freq * 3 * t)\n",
        "            )\n",
        "\n",
        "            # Envelope (fade in/out)\n",
        "            envelope = np.concatenate([\n",
        "                np.linspace(0, 1, int(samples_per_beat * 0.1)),\n",
        "                np.linspace(1, 0.8, int(samples_per_beat * 0.8)),\n",
        "                np.linspace(0.8, 0, int(samples_per_beat * 0.1))\n",
        "            ])\n",
        "\n",
        "            tone *= envelope[:len(tone)]\n",
        "            audio = np.concatenate([audio, tone])\n",
        "\n",
        "        # Add drum pattern\n",
        "        audio = self._add_drums(audio, tempo, duration)\n",
        "\n",
        "        return audio\n",
        "\n",
        "    def _add_drums(self, audio: np.ndarray, tempo: int, duration: int) -> np.ndarray:\n",
        "        \"\"\"Add simple drum beat\"\"\"\n",
        "        beat_duration = 60 / tempo\n",
        "        samples_per_beat = int(self.sr * beat_duration)\n",
        "\n",
        "        drums = np.zeros_like(audio)\n",
        "\n",
        "        # Kick on beats 0, 2\n",
        "        # Snare on beats 1, 3\n",
        "        num_beats = int(duration * tempo / 60)\n",
        "\n",
        "        for beat in range(num_beats):\n",
        "            start_sample = beat * samples_per_beat\n",
        "            end_sample = min(start_sample + samples_per_beat, len(drums))\n",
        "\n",
        "            if beat % 2 == 0:  # Kick drum\n",
        "                freq = 80\n",
        "                decay = 0.3\n",
        "            else:  # Snare\n",
        "                freq = 200\n",
        "                decay = 0.15\n",
        "\n",
        "            t = np.linspace(0, decay, end_sample - start_sample)\n",
        "            drum_sound = np.sin(2 * np.pi * freq * t) * np.exp(-t / decay)\n",
        "\n",
        "            drums[start_sample:end_sample] += drum_sound[:end_sample - start_sample] * 0.3\n",
        "\n",
        "        # Mix (80% melody, 20% drums)\n",
        "        return 0.8 * audio + 0.2 * drums\n",
        "\n",
        "    def save(self, audio: np.ndarray, path: str):\n",
        "        \"\"\"Save audio\"\"\"\n",
        "        audio = audio / (np.max(np.abs(audio)) + 1e-7)\n",
        "        sf.write(path, audio, self.sr)\n",
        "        print(f\"âœ“ Saved: {path}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# HYBRID GENERATOR - VOCALS + MUSIC + MIXING\n",
        "# ============================================================================\n",
        "\n",
        "class IndustrialMusicGenerator:\n",
        "    \"\"\"\n",
        "    Production-grade generator\n",
        "    - Piper TTS for vocals\n",
        "    - Music synthesis or Jukebox\n",
        "    - Advanced mixing with librosa\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device: torch.device, use_jukebox: bool = False):\n",
        "        self.device = device\n",
        "\n",
        "        print(\"=\" * 70)\n",
        "        print(\"ðŸŽµ INDUSTRIAL-GRADE MUSIC GENERATOR\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # TTS (always available)\n",
        "        self.tts = PiperTTS(device, voice=\"en_US-bryce-medium\")\n",
        "\n",
        "        # Music generator\n",
        "        if use_jukebox:\n",
        "            try:\n",
        "                self.music_gen = JukeboxMusicGen(device)\n",
        "                print(\"âœ“ Using Jukebox for music generation\")\n",
        "            except:\n",
        "                print(\"âš ï¸  Jukebox unavailable, using synthesis fallback\")\n",
        "                self.music_gen = SynthesisMusicGen()\n",
        "        else:\n",
        "            self.music_gen = SynthesisMusicGen()\n",
        "\n",
        "    def generate_song(\n",
        "        self,\n",
        "        lyrics: str,\n",
        "        music_description: str = \"upbeat pop\",\n",
        "        duration: int = 60,\n",
        "        vocal_weight: float = 0.65,\n",
        "        output_path: str = \"output.wav\"\n",
        "    ) -> Tuple[np.ndarray, str]:\n",
        "        \"\"\"\n",
        "        Generate complete song with vocals + music\n",
        "\n",
        "        Args:\n",
        "            lyrics: Song lyrics\n",
        "            music_description: Music style description\n",
        "            duration: Total duration in seconds\n",
        "            vocal_weight: Vocal volume (0-1, higher = louder vocals)\n",
        "            output_path: Output file path\n",
        "\n",
        "        Returns:\n",
        "            (audio_array, output_path)\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"ðŸŽ¬ SONG GENERATION PIPELINE\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Step 1: Generate vocals\n",
        "        print(\"\\n[1/4] Generating vocals...\")\n",
        "        print(f\"  Text: {len(lyrics)} characters\")\n",
        "        vocals = self.tts.generate_long(lyrics, chunk_size=400)\n",
        "        vocal_sr = self.tts.sample_rate\n",
        "        vocal_duration = len(vocals) / vocal_sr\n",
        "        print(f\"  âœ“ Vocals generated: {vocal_duration:.1f}s @ {vocal_sr}Hz\")\n",
        "\n",
        "        # Step 2: Generate music\n",
        "        print(\"\\n[2/4] Generating music...\")\n",
        "        if hasattr(self.music_gen, 'sr'):\n",
        "            # Synthesis\n",
        "            music = self.music_gen.generate_melody(\n",
        "                duration=max(int(vocal_duration) + 5, duration),\n",
        "                tempo=120,\n",
        "                scale=\"major\"\n",
        "            )\n",
        "            music_sr = self.music_gen.sr\n",
        "        else:\n",
        "            # Jukebox\n",
        "            music = self.music_gen.generate(music_description, duration_seconds=duration)\n",
        "            music_sr = self.music_gen.SAMPLE_RATE\n",
        "\n",
        "        music_duration = len(music) / music_sr\n",
        "        print(f\"  âœ“ Music generated: {music_duration:.1f}s @ {music_sr}Hz\")\n",
        "\n",
        "        # Step 3: Resample to common rate\n",
        "        print(\"\\n[3/4] Resampling...\")\n",
        "        target_sr = 44100\n",
        "\n",
        "        if vocal_sr != target_sr:\n",
        "            vocals = librosa.resample(vocals, orig_sr=vocal_sr, target_sr=target_sr)\n",
        "            print(f\"  âœ“ Vocals resampled to {target_sr}Hz\")\n",
        "\n",
        "        if music_sr != target_sr:\n",
        "            music = librosa.resample(music, orig_sr=music_sr, target_sr=target_sr)\n",
        "            print(f\"  âœ“ Music resampled to {target_sr}Hz\")\n",
        "\n",
        "        # Match lengths\n",
        "        min_length = min(len(vocals), len(music))\n",
        "        vocals = vocals[:min_length]\n",
        "        music = music[:min_length]\n",
        "\n",
        "        # Step 4: Mix\n",
        "        print(\"\\n[4/4] Mixing...\")\n",
        "        mixed = vocal_weight * vocals + (1 - vocal_weight) * music\n",
        "        mixed = mixed / (np.max(np.abs(mixed)) + 1e-7)\n",
        "\n",
        "        final_duration = len(mixed) / target_sr\n",
        "        print(f\"  âœ“ Mixed | Duration: {final_duration:.1f}s | SR: {target_sr}Hz\")\n",
        "        print(f\"  âœ“ Vocal level: {vocal_weight*100:.0f}% | Music level: {(1-vocal_weight)*100:.0f}%\")\n",
        "\n",
        "        # Save\n",
        "        print(f\"\\n[5/4] Saving...\")\n",
        "        mixed_int16 = (mixed * 32767).astype(np.int16)\n",
        "        write_wav(output_path, target_sr, mixed_int16)\n",
        "\n",
        "        file_size_mb = os.path.getsize(output_path) / 1e6\n",
        "        print(f\"  âœ“ Saved: {output_path} ({file_size_mb:.1f}MB)\")\n",
        "\n",
        "        return mixed, output_path\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXAMPLE\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = KaggleSetup.init()\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = IndustrialMusicGenerator(device, use_jukebox=False)\n",
        "\n",
        "    # Example: Generate a song\n",
        "    lyrics = \"\"\"\n",
        "    [Verse 1]\n",
        "    Waking up in the morning light, the sun is shining bright,\n",
        "    Today's a day to chase my dreams, everything's possible.\n",
        "\n",
        "    [Chorus]\n",
        "    I'm flying high, reaching for the sky,\n",
        "    Never gonna let it go, watch my spirit flying,\n",
        "    Reaching for the stars, never gonna fall,\n",
        "    This is my moment, I have it all.\n",
        "\n",
        "    [Verse 2]\n",
        "    Dancing through the city streets, moving to the beat,\n",
        "    Life is beautiful and free, this is all I need to be.\n",
        "\n",
        "    [Chorus]\n",
        "    I'm flying high, reaching for the sky,\n",
        "    Never gonna let it go, watch my spirit flying,\n",
        "    Reaching for the stars, never gonna fall,\n",
        "    This is my moment, I have it all.\n",
        "    \"\"\"\n",
        "\n",
        "    audio, path = generator.generate_song(\n",
        "        lyrics=lyrics,\n",
        "        music_description=\"upbeat energetic pop with drums and synths\",\n",
        "        duration=60,\n",
        "        vocal_weight=0.65,\n",
        "        output_path=\"/kaggle/working/song.wav\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"âœ“ GENERATION COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Output: {path}\")\n"
      ],
      "metadata": {
        "id": "PzFUQmLV83hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jualS9x584Ns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}